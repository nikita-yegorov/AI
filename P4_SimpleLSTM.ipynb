{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from nltk import word_tokenize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.metrics import f1_score\n",
    "from torch import optim\n",
    "import torchtext\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import copy, time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = torchtext.data.Field(lower=True, batch_first=True, tokenize=word_tokenize)\n",
    "qid = torchtext.data.Field()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34002894163131714\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "target = torchtext.data.Field(sequential=False, use_vocab=False, is_target=True)\n",
    "train = torchtext.data.TabularDataset(path='./data/Quora/train.csv', format='csv',\n",
    "                                      fields={'question_text': ('text',text),\n",
    "                                              'target': ('target',target)})\n",
    "test = torchtext.data.TabularDataset(path='./data/Quora/test.csv', format='csv',\n",
    "                                     fields={'qid': ('qid', qid),\n",
    "                                             'question_text': ('text', text)})\n",
    "end = time.time()\n",
    "print((end - start)/ 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.build_vocab(train, test, min_freq=3)\n",
    "qid.build_vocab(test)\n",
    "text.vocab.load_vectors(torchtext.vocab.\n",
    "                        Vectors(r'C:\\Users\\Nikita\\PycharmProjects\\Sem_2\\data\\glove.6B.50d.txt'))\n",
    "\n",
    "random.seed(42)\n",
    "train, val = train.split(split_ratio=0.9, random_state=random.getstate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = torchtext.data.BucketIterator(dataset=train,\n",
    "                                               batch_size=batch_size,\n",
    "                                               sort_key=lambda x: x.text.__len__(),\n",
    "                                               shuffle=True,\n",
    "                                               sort=False)\n",
    "val_iter = torchtext.data.BucketIterator(dataset=val,\n",
    "                                             batch_size=batch_size,\n",
    "                                             sort_key=lambda x: x.text.__len__(),\n",
    "                                             train=False,\n",
    "                                             sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, pretrained_lm, padding_idx,  hidden_dim=128, lstm_layer=2, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = nn.Embedding.from_pretrained(pretrained_lm)\n",
    "        self.embedding.padding_idx = padding_idx\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        self.lstm = nn.LSTM(input_size=self.embedding.embedding_dim,\n",
    "                            hidden_size=hidden_dim,\n",
    "                            num_layers=lstm_layer,)\n",
    "        self.hidden2label = nn.Linear(hidden_dim * lstm_layer , 1)\n",
    "\n",
    "    def forward(self, sents):\n",
    "        x = self.embedding(sents)\n",
    "        x = torch.transpose(x, dim0=1, dim1=0)\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "        cat = torch.cat([c_n[i, :, :] for i in range(c_n.shape[0])], dim=1)\n",
    "        y = self.hidden2label(cat)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(num_epochs, model, loss_func, optimizer, train_iter, val_iter):\n",
    "    \n",
    "    step = 0\n",
    "    train_record = []\n",
    "    val_record = []\n",
    "     \n",
    "    for epoch in range(num_epochs):\n",
    "        tr_loss = []\n",
    "        for train_batch in iter(train_iter):\n",
    "            step += 1\n",
    "            model.train()\n",
    "            x = train_batch.text.cuda()\n",
    "            y = train_batch.target.type(torch.Tensor).cuda()\n",
    "            model.zero_grad()\n",
    "            pred = model.forward(x)\n",
    "            loss = loss_function(pred.view(-1), y)\n",
    "            tr_loss.append(loss.cpu().data.numpy())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if step % 100 == 0 :\n",
    "                model.eval()\n",
    "                model.zero_grad()\n",
    "                val_loss = []\n",
    "                for val_batch in iter(val_iter):\n",
    "                    \n",
    "                    val_x = val_batch.text.cuda()\n",
    "                    val_y = val_batch.target.type(torch.Tensor).cuda()\n",
    "                    val_pred = model.forward(val_x).view(-1)\n",
    "                    val_loss.append(loss_function(val_pred, val_y).cpu().data.numpy())\n",
    "                    \n",
    "                val_record.append({'step': step, 'loss': np.mean(val_loss)})\n",
    "                train_record.append({'step': step, 'loss':  np.mean(tr_loss)})\n",
    "\n",
    "                print('epoch {:02} - step {:06} - train_loss {:.4f} - val_loss {:.4f} '.format(\n",
    "                    epoch, step,  train_record[-1]['loss'], val_record[-1]['loss']))\n",
    "    return train_record, val_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_model = SimpleLSTM(text.vocab.vectors, lstm_layer=1, padding_idx=text.vocab.stoi[text.pad_token], \n",
    "                        hidden_dim=128).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, LSTM_model.parameters()),\n",
    "                    lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 00 - step 000100 - train_loss 0.2893 - val_loss 0.2488 \n",
      "epoch 00 - step 000200 - train_loss 0.2578 - val_loss 0.2404 \n",
      "epoch 00 - step 000300 - train_loss 0.2463 - val_loss 0.2359 \n",
      "epoch 00 - step 000400 - train_loss 0.2420 - val_loss 0.2499 \n",
      "epoch 00 - step 000500 - train_loss 0.2403 - val_loss 0.2294 \n",
      "epoch 00 - step 000600 - train_loss 0.2402 - val_loss 0.2514 \n",
      "epoch 00 - step 000700 - train_loss 0.2390 - val_loss 0.2450 \n",
      "epoch 00 - step 000800 - train_loss 0.2384 - val_loss 0.2443 \n",
      "epoch 00 - step 000900 - train_loss 0.2371 - val_loss 0.2395 \n",
      "epoch 00 - step 001000 - train_loss 0.2333 - val_loss 0.2229 \n",
      "epoch 01 - step 001100 - train_loss 0.1966 - val_loss 0.1891 \n",
      "epoch 01 - step 001200 - train_loss 0.1916 - val_loss 0.1813 \n",
      "epoch 01 - step 001300 - train_loss 0.1858 - val_loss 0.1849 \n",
      "epoch 01 - step 001400 - train_loss 0.1785 - val_loss 0.1738 \n",
      "epoch 01 - step 001500 - train_loss 0.1733 - val_loss 0.1713 \n",
      "epoch 01 - step 001600 - train_loss 0.1724 - val_loss 0.1720 \n",
      "epoch 01 - step 001700 - train_loss 0.1703 - val_loss 0.1687 \n",
      "epoch 01 - step 001800 - train_loss 0.1674 - val_loss 0.1656 \n",
      "epoch 01 - step 001900 - train_loss 0.1667 - val_loss 0.1703 \n",
      "epoch 01 - step 002000 - train_loss 0.1652 - val_loss 0.1619 \n",
      "epoch 01 - step 002100 - train_loss 0.1645 - val_loss 0.1674 \n",
      "epoch 02 - step 002200 - train_loss 0.1685 - val_loss 0.1610 \n",
      "epoch 02 - step 002300 - train_loss 0.1631 - val_loss 0.1609 \n",
      "epoch 02 - step 002400 - train_loss 0.1578 - val_loss 0.1577 \n",
      "epoch 02 - step 002500 - train_loss 0.1556 - val_loss 0.1634 \n",
      "epoch 02 - step 002600 - train_loss 0.1568 - val_loss 0.1587 \n",
      "epoch 02 - step 002700 - train_loss 0.1565 - val_loss 0.1586 \n",
      "epoch 02 - step 002800 - train_loss 0.1559 - val_loss 0.1665 \n",
      "epoch 02 - step 002900 - train_loss 0.1528 - val_loss 0.1552 \n",
      "epoch 02 - step 003000 - train_loss 0.1521 - val_loss 0.1641 \n",
      "epoch 02 - step 003100 - train_loss 0.1514 - val_loss 0.1701 \n",
      "epoch 03 - step 003200 - train_loss 0.1483 - val_loss 0.1590 \n",
      "epoch 03 - step 003300 - train_loss 0.1411 - val_loss 0.1521 \n",
      "epoch 03 - step 003400 - train_loss 0.1473 - val_loss 0.1532 \n",
      "epoch 03 - step 003500 - train_loss 0.1450 - val_loss 0.1539 \n",
      "epoch 03 - step 003600 - train_loss 0.1428 - val_loss 0.1504 \n",
      "epoch 03 - step 003700 - train_loss 0.1443 - val_loss 0.1578 \n",
      "epoch 03 - step 003800 - train_loss 0.1454 - val_loss 0.1500 \n",
      "epoch 03 - step 003900 - train_loss 0.1444 - val_loss 0.1499 \n",
      "epoch 03 - step 004000 - train_loss 0.1439 - val_loss 0.1479 \n",
      "epoch 03 - step 004100 - train_loss 0.1440 - val_loss 0.1468 \n",
      "epoch 03 - step 004200 - train_loss 0.1441 - val_loss 0.1491 \n",
      "epoch 04 - step 004300 - train_loss 0.1356 - val_loss 0.1530 \n",
      "epoch 04 - step 004400 - train_loss 0.1337 - val_loss 0.1452 \n",
      "epoch 04 - step 004500 - train_loss 0.1388 - val_loss 0.1650 \n",
      "epoch 04 - step 004600 - train_loss 0.1407 - val_loss 0.1559 \n",
      "epoch 04 - step 004700 - train_loss 0.1412 - val_loss 0.1451 \n",
      "epoch 04 - step 004800 - train_loss 0.1409 - val_loss 0.1446 \n",
      "epoch 04 - step 004900 - train_loss 0.1406 - val_loss 0.1493 \n",
      "epoch 04 - step 005000 - train_loss 0.1399 - val_loss 0.1474 \n",
      "epoch 04 - step 005100 - train_loss 0.1393 - val_loss 0.1456 \n",
      "epoch 04 - step 005200 - train_loss 0.1390 - val_loss 0.1455 \n",
      "epoch 05 - step 005300 - train_loss 0.0940 - val_loss 0.1493 \n",
      "epoch 05 - step 005400 - train_loss 0.1333 - val_loss 0.1449 \n",
      "epoch 05 - step 005500 - train_loss 0.1281 - val_loss 0.1526 \n",
      "epoch 05 - step 005600 - train_loss 0.1297 - val_loss 0.1442 \n",
      "epoch 05 - step 005700 - train_loss 0.1298 - val_loss 0.1445 \n",
      "epoch 05 - step 005800 - train_loss 0.1309 - val_loss 0.1419 \n",
      "epoch 05 - step 005900 - train_loss 0.1309 - val_loss 0.1416 \n",
      "epoch 05 - step 006000 - train_loss 0.1323 - val_loss 0.1434 \n",
      "epoch 05 - step 006100 - train_loss 0.1336 - val_loss 0.1432 \n",
      "epoch 05 - step 006200 - train_loss 0.1326 - val_loss 0.1493 \n",
      "epoch 05 - step 006300 - train_loss 0.1332 - val_loss 0.1404 \n",
      "epoch 06 - step 006400 - train_loss 0.1354 - val_loss 0.1424 \n",
      "epoch 06 - step 006500 - train_loss 0.1218 - val_loss 0.1444 \n",
      "epoch 06 - step 006600 - train_loss 0.1251 - val_loss 0.1457 \n",
      "epoch 06 - step 006700 - train_loss 0.1265 - val_loss 0.1459 \n",
      "epoch 06 - step 006800 - train_loss 0.1295 - val_loss 0.1413 \n",
      "epoch 06 - step 006900 - train_loss 0.1302 - val_loss 0.1397 \n",
      "epoch 06 - step 007000 - train_loss 0.1309 - val_loss 0.1397 \n",
      "epoch 06 - step 007100 - train_loss 0.1309 - val_loss 0.1405 \n",
      "epoch 06 - step 007200 - train_loss 0.1308 - val_loss 0.1471 \n",
      "epoch 06 - step 007300 - train_loss 0.1311 - val_loss 0.1466 \n",
      "epoch 06 - step 007400 - train_loss 0.1306 - val_loss 0.1378 \n",
      "epoch 07 - step 007500 - train_loss 0.1328 - val_loss 0.1448 \n",
      "epoch 07 - step 007600 - train_loss 0.1303 - val_loss 0.1390 \n",
      "epoch 07 - step 007700 - train_loss 0.1315 - val_loss 0.1418 \n",
      "epoch 07 - step 007800 - train_loss 0.1294 - val_loss 0.1399 \n",
      "epoch 07 - step 007900 - train_loss 0.1285 - val_loss 0.1390 \n",
      "epoch 07 - step 008000 - train_loss 0.1270 - val_loss 0.1391 \n",
      "epoch 07 - step 008100 - train_loss 0.1290 - val_loss 0.1389 \n",
      "epoch 07 - step 008200 - train_loss 0.1297 - val_loss 0.1397 \n",
      "epoch 07 - step 008300 - train_loss 0.1286 - val_loss 0.1524 \n",
      "epoch 07 - step 008400 - train_loss 0.1278 - val_loss 0.1357 \n",
      "epoch 08 - step 008500 - train_loss 0.1221 - val_loss 0.1407 \n",
      "epoch 08 - step 008600 - train_loss 0.1247 - val_loss 0.1374 \n",
      "epoch 08 - step 008700 - train_loss 0.1254 - val_loss 0.1355 \n",
      "epoch 08 - step 008800 - train_loss 0.1239 - val_loss 0.1438 \n",
      "epoch 08 - step 008900 - train_loss 0.1240 - val_loss 0.1381 \n",
      "epoch 08 - step 009000 - train_loss 0.1234 - val_loss 0.1377 \n",
      "epoch 08 - step 009100 - train_loss 0.1230 - val_loss 0.1445 \n",
      "epoch 08 - step 009200 - train_loss 0.1246 - val_loss 0.1532 \n",
      "epoch 08 - step 009300 - train_loss 0.1246 - val_loss 0.1364 \n",
      "epoch 08 - step 009400 - train_loss 0.1247 - val_loss 0.1353 \n",
      "epoch 08 - step 009500 - train_loss 0.1242 - val_loss 0.1347 \n",
      "epoch 09 - step 009600 - train_loss 0.1270 - val_loss 0.1360 \n",
      "epoch 09 - step 009700 - train_loss 0.1224 - val_loss 0.1461 \n",
      "epoch 09 - step 009800 - train_loss 0.1209 - val_loss 0.1348 \n",
      "epoch 09 - step 009900 - train_loss 0.1199 - val_loss 0.1425 \n",
      "epoch 09 - step 010000 - train_loss 0.1191 - val_loss 0.1356 \n",
      "epoch 09 - step 010100 - train_loss 0.1206 - val_loss 0.1353 \n",
      "epoch 09 - step 010200 - train_loss 0.1203 - val_loss 0.1395 \n",
      "epoch 09 - step 010300 - train_loss 0.1215 - val_loss 0.1362 \n",
      "epoch 09 - step 010400 - train_loss 0.1212 - val_loss 0.1357 \n",
      "epoch 09 - step 010500 - train_loss 0.1211 - val_loss 0.1377 \n",
      "7.106146641572317\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "t_record, v_record = training(model=LSTM_model, num_epochs=num_epochs, \n",
    "         loss_func = loss_function, optimizer=optimizer, train_iter=train_iter,\n",
    "        val_iter=val_iter)\n",
    "\n",
    "end = time.time()\n",
    "print((end - start)/ 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 105)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [ t_record[i]['loss']  for i in range(len(t_record))]\n",
    "v = [ v_record[i]['loss']  for i in range(len(t_record))]\n",
    "len(v), len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(0, len(t))\n",
    "plt.plot(x, t, 'b', label='Training loss')\n",
    "plt.plot(x, v, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_model.eval()\n",
    "val_pred = []\n",
    "val_true = []\n",
    "val_iter.init_epoch()\n",
    "for val_batch in iter(val_iter):\n",
    "    val_x = val_batch.text.cuda()\n",
    "    val_true += val_batch.target.data.numpy().tolist()\n",
    "    val_pred += torch.sigmoid(LSTM_model.forward(val_x).view(-1)).cpu().data.numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best threshold is 0.3100 with F1 score: 0.6172\n"
     ]
    }
   ],
   "source": [
    "tmp = [0,0,0] \n",
    "delta = 0\n",
    "for tmp[0] in np.arange(0.1, 0.501, 0.01):\n",
    "    tmp[1] = f1_score(val_true, np.array(val_pred)>tmp[0])\n",
    "    if tmp[1] > tmp[2]:\n",
    "        delta = tmp[0]\n",
    "        tmp[2] = tmp[1]\n",
    "print('best threshold is {:.4f} with F1 score: {:.4f}'.format(delta, tmp[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
